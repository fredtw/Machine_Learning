{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Building A classification with PySpark and MLlib\n",
    "# Breast Cancer Wisconsin case\n",
    "##### @ author Frederic TWAHIRWA\n",
    "\n",
    "### in this notebook , Decision Tree, Gradient-Boosted Tree and Random Forest Classier are going to be used.\n",
    "\n",
    "## Decision Tree\n",
    "Decision trees are widely used since they are easy to interpret, handle categorical features, extend to the multiclass classification setting, do not require feature scaling, and are able to capture non-linearities and feature interactions\n",
    "\n",
    "## Ensemble Models : Gradient-Boosted Tree and Random Forest\n",
    "An ensemble method is a learning algorithm which creates a model composed of a set of other base models. spark.mllib supports two major ensemble algorithms: GradientBoostedTrees and RandomForest. Both use decision trees as their base models\n",
    "\n",
    "## Gradient-Boosted Tree and Random Forest\n",
    "Both Gradient-Boosted Trees (GBTs) and Random Forests are algorithms for learning ensembles of trees, but the training processes are different. There are several practical trade-offs:\n",
    "\n",
    "- GBTs train one tree at a time, so they can take longer to train than random forests. Random Forests can train multiple trees in parallel.\n",
    "- On the other hand, it is often reasonable to use smaller (shallower) trees with GBTs than with Random Forests, and training smaller trees takes less time.\n",
    "- Random Forests can be less prone to overfitting. Training more trees in a Random Forest reduces the likelihood of overfitting, but training more trees with GBTs increases the likelihood of overfitting. (In statistical language, Random Forests reduce variance by using more trees, whereas GBTs reduce bias by using more trees.)\n",
    "- Random Forests can be easier to tune since performance improves monotonically with the number of trees (whereas performance can start to decrease for GBTs if the number of trees grows too large).\n",
    "\n",
    "- In short, both algorithms can be effective, and the choice should be based on the particular dataset.\n",
    "\n",
    "reference : Apache Spark (https://spark.apache.org/docs/2.2.0/mllib-ensembles.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast Cancer Wisconsin (Diagnostic) Data Set\n",
    "\n",
    "For this example we Data set \"Breast Cancer Wisconsin (Diagnostic)\" from \"UCI Machine learning repository  :(https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic) is going to be used. \n",
    "1 column : ID number; \n",
    "2 column : Diagnosis (M: Malignant, B=benign); \n",
    "3-30 columns : features (results of some analysis and measurements); \n",
    "more information : https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .Builder()\\\n",
    "        .appName(\"ClassificationExample\")\\\n",
    "        .getOrCreate() # required for dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## !wget https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "842302,M,17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189\n"
     ]
    }
   ],
   "source": [
    "# show head\n",
    "!head -n 1 ./Documents/MachineLearning/Breast_cancer_wisconsin/wdbc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 ./Documents/MachineLearning/Breast_cancer_wisconsin/wdbc.data\n"
     ]
    }
   ],
   "source": [
    "#count number of line\n",
    "!wc -l ./Documents/MachineLearning/Breast_cancer_wisconsin/wdbc.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Vectors to create local vector (there are 2 types of vectors : dense, sparse)\n",
    "# import StringIndexer to trasform a string in a number\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a text file and convert each line to a Row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a text file and convert each line to a Row.\n",
    "\n",
    "data_list = []\n",
    "\n",
    "with open(\"./Documents/MachineLearning/Breast_cancer_wisconsin/wdbc.data\") as infile:\n",
    "    for line in infile:\n",
    "        tokens = line.rstrip(\"\\n\").split(\",\")        \n",
    "        y = tokens[1]\n",
    "        features = Vectors.dense([float(x) for x in tokens[2:]])        \n",
    "        \n",
    "        data_list.append((y, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a DataFrame\n",
    "inputDF = spark.createDataFrame(data_list, [\"label\", \"features\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>[17.99, 10.38, 122.8, 1001.0, 0.1184, 0.2776, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>[20.57, 17.77, 132.9, 1326.0, 0.08474, 0.07864...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>[19.69, 21.25, 130.0, 1203.0, 0.1096, 0.1599, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>[11.42, 20.38, 77.58, 386.1, 0.1425, 0.2839, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>[20.29, 14.34, 135.1, 1297.0, 0.1003, 0.1328, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M</td>\n",
       "      <td>[12.45, 15.7, 82.57, 477.1, 0.1278, 0.17, 0.15...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M</td>\n",
       "      <td>[18.25, 19.98, 119.6, 1040.0, 0.09463, 0.109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M</td>\n",
       "      <td>[13.71, 20.83, 90.2, 577.9, 0.1189, 0.1645, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M</td>\n",
       "      <td>[13.0, 21.82, 87.5, 519.8, 0.1273, 0.1932, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M</td>\n",
       "      <td>[12.46, 24.04, 83.97, 475.9, 0.1186, 0.2396, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                           features\n",
       "0     M  [17.99, 10.38, 122.8, 1001.0, 0.1184, 0.2776, ...\n",
       "1     M  [20.57, 17.77, 132.9, 1326.0, 0.08474, 0.07864...\n",
       "2     M  [19.69, 21.25, 130.0, 1203.0, 0.1096, 0.1599, ...\n",
       "3     M  [11.42, 20.38, 77.58, 386.1, 0.1425, 0.2839, 0...\n",
       "4     M  [20.29, 14.34, 135.1, 1297.0, 0.1003, 0.1328, ...\n",
       "5     M  [12.45, 15.7, 82.57, 477.1, 0.1278, 0.17, 0.15...\n",
       "6     M  [18.25, 19.98, 119.6, 1040.0, 0.09463, 0.109, ...\n",
       "7     M  [13.71, 20.83, 90.2, 577.9, 0.1189, 0.1645, 0....\n",
       "8     M  [13.0, 21.82, 87.5, 519.8, 0.1273, 0.1932, 0.1...\n",
       "9     M  [12.46, 24.04, 83.97, 475.9, 0.1186, 0.2396, 0..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show the DataFrame\n",
    "#inputDF.show()\n",
    "inputDF.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# indexing the label (M=>1, B=>0)\n",
    "stringIndexer = StringIndexer(inputCol = \"label\", outputCol = \"labelIndexed\")\n",
    "si_model = stringIndexer.fit(inputDF)\n",
    "inputDF2 = si_model.transform(inputDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------------+\n",
      "|label|            features|labelIndexed|\n",
      "+-----+--------------------+------------+\n",
      "|    M|[17.99,10.38,122....|         1.0|\n",
      "|    M|[20.57,17.77,132....|         1.0|\n",
      "|    M|[19.69,21.25,130....|         1.0|\n",
      "|    M|[11.42,20.38,77.5...|         1.0|\n",
      "|    M|[20.29,14.34,135....|         1.0|\n",
      "|    M|[12.45,15.7,82.57...|         1.0|\n",
      "|    M|[18.25,19.98,119....|         1.0|\n",
      "|    M|[13.71,20.83,90.2...|         1.0|\n",
      "|    M|[13.0,21.82,87.5,...|         1.0|\n",
      "|    M|[12.46,24.04,83.9...|         1.0|\n",
      "|    M|[16.02,23.24,102....|         1.0|\n",
      "|    M|[15.78,17.89,103....|         1.0|\n",
      "|    M|[19.17,24.8,132.4...|         1.0|\n",
      "|    M|[15.85,23.95,103....|         1.0|\n",
      "|    M|[13.73,22.61,93.6...|         1.0|\n",
      "|    M|[14.54,27.54,96.7...|         1.0|\n",
      "|    M|[14.68,20.13,94.7...|         1.0|\n",
      "|    M|[16.13,20.68,108....|         1.0|\n",
      "|    M|[19.81,22.15,130....|         1.0|\n",
      "|    B|[13.54,14.36,87.4...|         0.0|\n",
      "+-----+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputDF2.show()\n",
    "#inputDF2.limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = inputDF2.randomSplit([0.7, 0.3], seed = 57)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import Decision Tree classifier and classification Evaluator\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create a class which is responsible for training and test\n",
    "decisionTree = DecisionTreeClassifier(labelCol = \"labelIndexed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# call the method fit to the training data, and obtain a decision tree model\n",
    "dtModel = decisionTree.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### some results (number of nodes, depth, features importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of node are : 27\n",
      "the depth of the model is  : 5\n",
      "features importances  : (30,[1,4,7,10,16,21,23,27,29],[0.0374235426794,0.038778742902,0.00541570897648,0.0140606515278,0.0046629181201,0.065269843249,0.690521755556,0.125268152215,0.0185986847745])\n",
      "Number of features  : 30\n"
     ]
    }
   ],
   "source": [
    "#number of node\n",
    "print (\"Numbers of node are : {}\".format(dtModel.numNodes))\n",
    "print (\"the depth of the model is  : {}\".format(dtModel.depth))\n",
    "print (\"features importances  : {}\".format(dtModel.featureImportances))\n",
    "print (\"Number of features  : {}\".format(dtModel.numFeatures))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The feature \"23\" seems to be the most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4018ad760d13159556da) of depth 5 with 27 nodes\n",
      "  If (feature 23 <= 877.0)\n",
      "   If (feature 27 <= 0.13495000000000001)\n",
      "    If (feature 10 <= 0.7658)\n",
      "     If (feature 27 <= 0.11085)\n",
      "      If (feature 10 <= 0.6265499999999999)\n",
      "       Predict: 0.0\n",
      "      Else (feature 10 > 0.6265499999999999)\n",
      "       Predict: 0.0\n",
      "     Else (feature 27 > 0.11085)\n",
      "      If (feature 29 <= 0.07909)\n",
      "       Predict: 1.0\n",
      "      Else (feature 29 > 0.07909)\n",
      "       Predict: 0.0\n",
      "    Else (feature 10 > 0.7658)\n",
      "     Predict: 1.0\n",
      "   Else (feature 27 > 0.13495000000000001)\n",
      "    If (feature 21 <= 25.674999999999997)\n",
      "     If (feature 4 <= 0.12455)\n",
      "      If (feature 16 <= 0.032535)\n",
      "       Predict: 0.0\n",
      "      Else (feature 16 > 0.032535)\n",
      "       Predict: 0.0\n",
      "     Else (feature 4 > 0.12455)\n",
      "      Predict: 1.0\n",
      "    Else (feature 21 > 25.674999999999997)\n",
      "     Predict: 1.0\n",
      "  Else (feature 23 > 877.0)\n",
      "   If (feature 1 <= 15.705)\n",
      "    If (feature 4 <= 0.096245)\n",
      "     Predict: 0.0\n",
      "    Else (feature 4 > 0.096245)\n",
      "     Predict: 1.0\n",
      "   Else (feature 1 > 15.705)\n",
      "    If (feature 7 <= 0.027985000000000003)\n",
      "     If (feature 1 <= 19.64)\n",
      "      Predict: 0.0\n",
      "     Else (feature 1 > 19.64)\n",
      "      Predict: 1.0\n",
      "    Else (feature 7 > 0.027985000000000003)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualize the Decision Tree\n",
    "print (dtModel.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of the Decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_dt = dtModel.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>labelIndexed</th>\n",
       "      <th>probability</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.995555555556, 0.00444444444444]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 0.0]</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  labelIndexed                         probability  prediction\n",
       "0      B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "1      B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "2      B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "3      B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "4      B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "5      B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "6      B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "7      B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "8      B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "9      B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "10     B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "11     B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "12     B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "13     B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "14     B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "15     B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "16     B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "17     B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "18     B           0.0  [0.995555555556, 0.00444444444444]         0.0\n",
       "19     B           0.0                          [1.0, 0.0]         0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions_dt.select('label', 'labelIndexed', 'probability', 'prediction').show()\n",
    "predictions_dt.select('label', 'labelIndexed', 'probability', 'prediction').limit(20).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.054878\n"
     ]
    }
   ],
   "source": [
    "evaluator_dt = MulticlassClassificationEvaluator(labelCol = \"labelIndexed\",\\\n",
    "                                                 predictionCol = \"prediction\",\\\n",
    "                                                 metricName = \"accuracy\")\n",
    "accuracy_dt = evaluator_dt.evaluate(predictions_dt)\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import MulticlassMetrics to compute matrix Confusion\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictionsAndLabels_dt= predictions_dt.select(\"prediction\", \"labelIndexed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9451219512195121"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dt = MulticlassMetrics(predictionsAndLabels_dt.rdd)\n",
    "metrics_dt.accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 92.,   7.],\n",
       "       [  2.,  63.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dt.confusionMatrix().toArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import BinaryClassificationsMetrics to compute area Under ROC\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9492618492618493"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_dt_bc = BinaryClassificationMetrics(predictionsAndLabels_dt.rdd)\n",
    "metrics_dt_bc.areaUnderROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### decision tree (with default parameters) gives a model with 94.5% af accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Decison Tree (GBDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#   import GBT classiefier\n",
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+--------------------+----------+\n",
      "|label|labelIndexed|         probability|prediction|\n",
      "+-----+------------+--------------------+----------+\n",
      "|    B|         0.0|[0.97851682222474...|       0.0|\n",
      "|    B|         0.0|[0.97871014383998...|       0.0|\n",
      "|    B|         0.0|[0.97866117079892...|       0.0|\n",
      "|    B|         0.0|[0.97871014383998...|       0.0|\n",
      "|    B|         0.0|[0.97871014383998...|       0.0|\n",
      "|    B|         0.0|[0.97835010698528...|       0.0|\n",
      "|    B|         0.0|[0.97871014383998...|       0.0|\n",
      "|    B|         0.0|[0.97868210148285...|       0.0|\n",
      "|    B|         0.0|[0.97866117079892...|       0.0|\n",
      "|    B|         0.0|[0.97856611929318...|       0.0|\n",
      "+-----+------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create the object \n",
    "gbdt = GBTClassifier(labelCol = \"labelIndexed\", featuresCol = \"features\", maxIter = 50, stepSize = 0.1)\n",
    "gbdtModel = gbdt.fit(trainingData)\n",
    "prediction_gbdt = gbdtModel.transform(testData)\n",
    "prediction_gbdt.select('label', 'labelIndexed', 'probability', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the GBDT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy with the GBDT model is : 0.9512195121951219\n",
      "the Area under ROC  with the GBDT model is : 0.9516705516705518\n",
      " The matrix confustion with the GBDT model :\n",
      "[[ 94.   5.]\n",
      " [  3.  62.]]\n"
     ]
    }
   ],
   "source": [
    "predictionsAndLabels_gbdt= prediction_gbdt.select(\"prediction\", \"labelIndexed\")\n",
    "metrics_gbdt = MulticlassMetrics(predictionsAndLabels_gbdt.rdd)\n",
    "metrics_gbdt_bc = BinaryClassificationMetrics(predictionsAndLabels_gbdt.rdd)\n",
    "print (\"the accuracy with the GBDT model is : {}\".format(metrics_gbdt.accuracy))\n",
    "print (\"the Area under ROC  with the GBDT model is : {}\".format(metrics_gbdt_bc.areaUnderROC))\n",
    "print ( \" The matrix confustion with the GBDT model :\")\n",
    "print (metrics_gbdt.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(30, {0: 0.0122, 1: 0.0218, 2: 0.0, 3: 0.0, 4: 0.0205, 5: 0.0198, 6: 0.0046, 7: 0.0039, 8: 0.0, 9: 0.0, 10: 0.0054, 11: 0.012, 12: 0.0115, 13: 0.0126, 14: 0.01, 15: 0.0206, 16: 0.0031, 17: 0.002, 18: 0.0, 19: 0.0014, 20: 0.002, 21: 0.0743, 22: 0.0054, 23: 0.603, 24: 0.0212, 25: 0.0033, 26: 0.0086, 27: 0.1173, 28: 0.0023, 29: 0.0011})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Features Importances\n",
    "gbdtModel.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with the GBDT model, the feature \"23\" is also the most important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM FOREST model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## import RAndom forest packages\n",
    "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Train the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfClassifer = RandomForestClassifier(labelCol = \"labelIndexed\", numTrees = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+--------------------+----------+\n",
      "|label|labelIndexed|         probability|prediction|\n",
      "+-----+------------+--------------------+----------+\n",
      "|    B|         0.0|[0.99813186528588...|       0.0|\n",
      "|    B|         0.0|[0.99863027038954...|       0.0|\n",
      "|    B|         0.0|[0.99775307740709...|       0.0|\n",
      "|    B|         0.0|[0.99779010009827...|       0.0|\n",
      "|    B|         0.0|[0.99855451281379...|       0.0|\n",
      "|    B|         0.0|[0.99668347687298...|       0.0|\n",
      "|    B|         0.0|[0.99855451281379...|       0.0|\n",
      "|    B|         0.0|[0.96894575917046...|       0.0|\n",
      "|    B|         0.0|[0.99775307740709...|       0.0|\n",
      "|    B|         0.0|[0.99900905826833...|       0.0|\n",
      "+-----+------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfModel = rfClassifer.fit(trainingData)\n",
    "prediction_rf = rfModel.transform(testData)\n",
    "prediction_rf.select('label', 'labelIndexed', 'probability', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy with the Random Forest  model is : 0.9695121951219512\n",
      "The Area under ROC  with the Random Forest model is : 0.9694638694638695\n",
      "The matrix confustion with the Random Forest model is :\n",
      "[[ 96.   3.]\n",
      " [  2.  63.]]\n"
     ]
    }
   ],
   "source": [
    "predictionsAndLabels_rf= prediction_rf.select(\"prediction\", \"labelIndexed\")\n",
    "metrics_rf = MulticlassMetrics(predictionsAndLabels_rf.rdd)\n",
    "metrics_rf_bc = BinaryClassificationMetrics(predictionsAndLabels_rf.rdd)\n",
    "print (\"The accuracy with the Random Forest  model is : {}\".format(metrics_rf.accuracy))\n",
    "print (\"The Area under ROC  with the Random Forest model is : {}\".format(metrics_rf_bc.areaUnderROC))\n",
    "print ( \"The matrix confustion with the Random Forest model is :\")\n",
    "print (metrics_rf.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setting some parameters to optimize performancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfClassifer2 = RandomForestClassifier(labelCol = \"labelIndexed\",\\\n",
    "                                      #numTrees = 40,\\\n",
    "                                     impurity =\"gini\", \\\n",
    "                                     maxDepth = 30) # DecisionTree currently only supports maxDepth <= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------+-----------+----------+\n",
      "|label|labelIndexed|probability|prediction|\n",
      "+-----+------------+-----------+----------+\n",
      "|    B|         0.0|  [1.0,0.0]|       0.0|\n",
      "|    B|         0.0|  [1.0,0.0]|       0.0|\n",
      "|    B|         0.0|  [1.0,0.0]|       0.0|\n",
      "|    B|         0.0|  [1.0,0.0]|       0.0|\n",
      "|    B|         0.0|  [1.0,0.0]|       0.0|\n",
      "|    B|         0.0|  [1.0,0.0]|       0.0|\n",
      "|    B|         0.0|  [1.0,0.0]|       0.0|\n",
      "|    B|         0.0|[0.95,0.05]|       0.0|\n",
      "|    B|         0.0|  [1.0,0.0]|       0.0|\n",
      "|    B|         0.0|  [1.0,0.0]|       0.0|\n",
      "+-----+------------+-----------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfModel2 = rfClassifer2.fit(trainingData)\n",
    "prediction_rf2 = rfModel2.transform(testData)\n",
    "prediction_rf2.select('label', 'labelIndexed', 'probability', 'prediction').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Evaluate the 2nd RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy with the Random Forest  model (the 2nd model)  is : 0.975609756097561\n",
      "The Area under ROC  with the Random Forest model (the 2nd model)is : 0.9771561771561772\n",
      "The matrix confustion with the Random Forest model (the 2nd model) is :\n",
      "[[ 96.   3.]\n",
      " [  1.  64.]]\n"
     ]
    }
   ],
   "source": [
    "predictionsAndLabels_rf2= prediction_rf2.select(\"prediction\", \"labelIndexed\")\n",
    "metrics_rf2 = MulticlassMetrics(predictionsAndLabels_rf2.rdd)\n",
    "metrics_rf2_bc = BinaryClassificationMetrics(predictionsAndLabels_rf2.rdd)\n",
    "print (\"The accuracy with the Random Forest  model (the 2nd model)  is : {}\".format(metrics_rf2.accuracy))\n",
    "print (\"The Area under ROC  with the Random Forest model (the 2nd model)is : {}\" \\\n",
    "       .format(metrics_rf2_bc.areaUnderROC))\n",
    "print ( \"The matrix confustion with the Random Forest model (the 2nd model) is :\")\n",
    "print (metrics_rf2.confusionMatrix().toArray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Given models above, random forest performed a little bit better on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "references : \n",
    "    \n",
    "- https://spark.apache.org/docs/2.2.0/mllib-ensembles.html\n",
    "- https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#decision-tree-classifier\n",
    "- https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#random-forest-classifier\n",
    "- https://spark.apache.org/docs/2.2.0/ml-classification-regression.html#gradient-boosted-tree-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
